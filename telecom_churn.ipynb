{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ko4gnvegCbmL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "EGzxiPtSGpzM",
    "outputId": "c6501c49-a1be-4b0d-f4bf-4831f6ba6bbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6     ...      sachet_3g_9  fb_user_6  \\\n",
       "0            9/30/2014  197.385     ...                0        1.0   \n",
       "1            9/30/2014   34.047     ...                0        NaN   \n",
       "2            9/30/2014  167.690     ...                0        NaN   \n",
       "3            9/30/2014  221.338     ...                0        NaN   \n",
       "4            9/30/2014  261.636     ...                0        0.0   \n",
       "\n",
       "   fb_user_7  fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        1.0        1.0        NaN   968        30.4         0.0      101.20   \n",
       "1        1.0        1.0        NaN  1006         0.0         0.0        0.00   \n",
       "2        NaN        NaN        1.0  1103         0.0         0.0        4.17   \n",
       "3        NaN        NaN        NaN  2491         0.0         0.0        0.00   \n",
       "4        NaN        NaN        NaN  1526         0.0         0.0        0.00   \n",
       "\n",
       "   sep_vbc_3g  \n",
       "0        3.58  \n",
       "1        0.00  \n",
       "2        0.00  \n",
       "3        0.00  \n",
       "4        0.00  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "churn = pd.read_csv('telecom_churn_data.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GG0uGuGeN6oL"
   },
   "outputs": [],
   "source": [
    "temp = churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "ctzUSUHvM1zz",
    "outputId": "ad21e50b-69e1-4aa3-9a7e-d8182603b71b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6  ...    fb_user_6  fb_user_7  fb_user_8  \\\n",
       "0            9/30/2014  197.385  ...          1.0        1.0        1.0   \n",
       "1            9/30/2014   34.047  ...          NaN        1.0        1.0   \n",
       "2            9/30/2014  167.690  ...          NaN        NaN        NaN   \n",
       "3            9/30/2014  221.338  ...          NaN        NaN        NaN   \n",
       "4            9/30/2014  261.636  ...          0.0        NaN        NaN   \n",
       "\n",
       "   fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  churn  \n",
       "0        NaN   968        30.4         0.0      101.20        3.58      1  \n",
       "1        NaN  1006         0.0         0.0        0.00        0.00      0  \n",
       "2        1.0  1103         0.0         0.0        4.17        0.00      0  \n",
       "3        NaN  2491         0.0         0.0        0.00        0.00      0  \n",
       "4        NaN  1526         0.0         0.0        0.00        0.00      0  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assign churn column based on the usage done in 9th month\n",
    "churn['churn'] = churn.apply(lambda x: 1 if (x['total_ic_mou_9'] == 0 and x['total_og_mou_9'] == 0 and x['vol_2g_mb_9'] == 0 and x['vol_3g_mb_9'] == 0) else 0, axis=1)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "-mdwIVIAPgR0",
    "outputId": "6ee32c94-291f-4373-850c-ffb1f7632f15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>21.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.047</td>\n",
       "      <td>355.074</td>\n",
       "      <td>268.321</td>\n",
       "      <td>86.285</td>\n",
       "      <td>24.11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.690</td>\n",
       "      <td>189.058</td>\n",
       "      <td>210.226</td>\n",
       "      <td>290.714</td>\n",
       "      <td>11.54</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.338</td>\n",
       "      <td>251.102</td>\n",
       "      <td>508.054</td>\n",
       "      <td>389.500</td>\n",
       "      <td>99.91</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.636</td>\n",
       "      <td>309.876</td>\n",
       "      <td>238.174</td>\n",
       "      <td>163.426</td>\n",
       "      <td>50.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "    arpu_6   arpu_7   arpu_8   arpu_9  onnet_mou_6  ...    fb_user_6  \\\n",
       "0  197.385  214.816  213.803   21.100          NaN  ...          1.0   \n",
       "1   34.047  355.074  268.321   86.285        24.11  ...          NaN   \n",
       "2  167.690  189.058  210.226  290.714        11.54  ...          NaN   \n",
       "3  221.338  251.102  508.054  389.500        99.91  ...          NaN   \n",
       "4  261.636  309.876  238.174  163.426        50.31  ...          0.0   \n",
       "\n",
       "   fb_user_7  fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        1.0        1.0        NaN   968        30.4         0.0      101.20   \n",
       "1        1.0        1.0        NaN  1006         0.0         0.0        0.00   \n",
       "2        NaN        NaN        1.0  1103         0.0         0.0        4.17   \n",
       "3        NaN        NaN        NaN  2491         0.0         0.0        0.00   \n",
       "4        NaN        NaN        NaN  1526         0.0         0.0        0.00   \n",
       "\n",
       "   sep_vbc_3g  churn  \n",
       "0        3.58      1  \n",
       "1        0.00      0  \n",
       "2        0.00      0  \n",
       "3        0.00      0  \n",
       "4        0.00      0  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop last date columns as it is not giving any important data\n",
    "churn.drop(columns=['last_date_of_month_6','last_date_of_month_7','last_date_of_month_8', 'last_date_of_month_9'], inplace=True)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1058
    },
    "colab_type": "code",
    "id": "F_xVvzrRQYgc",
    "outputId": "5dd73f12-7b2f-480c-a84a-a8c1b7101991"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobile_number       99999\n",
       "circle_id               1\n",
       "loc_og_t2o_mou          1\n",
       "std_og_t2o_mou          1\n",
       "loc_ic_t2o_mou          1\n",
       "arpu_6              85681\n",
       "arpu_7              85308\n",
       "arpu_8              83615\n",
       "arpu_9              79937\n",
       "onnet_mou_6         24313\n",
       "onnet_mou_7         24336\n",
       "onnet_mou_8         24089\n",
       "onnet_mou_9         23565\n",
       "offnet_mou_6        31140\n",
       "offnet_mou_7        31023\n",
       "offnet_mou_8        30908\n",
       "offnet_mou_9        30077\n",
       "roam_ic_mou_6        6512\n",
       "roam_ic_mou_7        5230\n",
       "roam_ic_mou_8        5315\n",
       "roam_ic_mou_9        4827\n",
       "roam_og_mou_6        8038\n",
       "roam_og_mou_7        6639\n",
       "roam_og_mou_8        6504\n",
       "roam_og_mou_9        5882\n",
       "loc_og_t2t_mou_6    13539\n",
       "loc_og_t2t_mou_7    13411\n",
       "loc_og_t2t_mou_8    13336\n",
       "loc_og_t2t_mou_9    12949\n",
       "loc_og_t2m_mou_6    20905\n",
       "                    ...  \n",
       "night_pck_user_6        2\n",
       "night_pck_user_7        2\n",
       "night_pck_user_8        2\n",
       "night_pck_user_9        2\n",
       "monthly_2g_6            5\n",
       "monthly_2g_7            6\n",
       "monthly_2g_8            6\n",
       "monthly_2g_9            5\n",
       "sachet_2g_6            32\n",
       "sachet_2g_7            35\n",
       "sachet_2g_8            34\n",
       "sachet_2g_9            32\n",
       "monthly_3g_6           12\n",
       "monthly_3g_7           15\n",
       "monthly_3g_8           12\n",
       "monthly_3g_9           11\n",
       "sachet_3g_6            25\n",
       "sachet_3g_7            27\n",
       "sachet_3g_8            29\n",
       "sachet_3g_9            27\n",
       "fb_user_6               2\n",
       "fb_user_7               2\n",
       "fb_user_8               2\n",
       "fb_user_9               2\n",
       "aon                  3489\n",
       "aug_vbc_3g          14676\n",
       "jul_vbc_3g          14162\n",
       "jun_vbc_3g          13312\n",
       "sep_vbc_3g           3720\n",
       "churn                   2\n",
       "Length: 223, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circle_id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loc_og_t2o_mou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std_og_t2o_mou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loc_ic_t2o_mou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>std_og_t2c_mou_6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>std_og_t2c_mou_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>std_og_t2c_mou_8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>std_og_t2c_mou_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>std_ic_t2o_mou_6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>std_ic_t2o_mou_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>std_ic_t2o_mou_8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>std_ic_t2o_mou_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              colName  count\n",
       "1           circle_id      1\n",
       "2      loc_og_t2o_mou      1\n",
       "3      std_og_t2o_mou      1\n",
       "4      loc_ic_t2o_mou      1\n",
       "57   std_og_t2c_mou_6      1\n",
       "58   std_og_t2c_mou_7      1\n",
       "59   std_og_t2c_mou_8      1\n",
       "60   std_og_t2c_mou_9      1\n",
       "109  std_ic_t2o_mou_6      1\n",
       "110  std_ic_t2o_mou_7      1\n",
       "111  std_ic_t2o_mou_8      1\n",
       "112  std_ic_t2o_mou_9      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(churn.nunique())\n",
    "temp = temp.reset_index()\n",
    "temp.rename(columns={0:\"count\", \"index\":\"colName\"}, inplace=True)\n",
    "temp1 = temp.loc[temp['count'] < 2]\n",
    "temp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdc_8MpPRI4D"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "pucvgPkeQxnu",
    "outputId": "f76c042f-d5e9-403a-d8d8-9ff1e3b1b8f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>21.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>34.047</td>\n",
       "      <td>355.074</td>\n",
       "      <td>268.321</td>\n",
       "      <td>86.285</td>\n",
       "      <td>24.11</td>\n",
       "      <td>78.68</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>15.74</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>167.690</td>\n",
       "      <td>189.058</td>\n",
       "      <td>210.226</td>\n",
       "      <td>290.714</td>\n",
       "      <td>11.54</td>\n",
       "      <td>55.24</td>\n",
       "      <td>37.26</td>\n",
       "      <td>74.81</td>\n",
       "      <td>143.33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>221.338</td>\n",
       "      <td>251.102</td>\n",
       "      <td>508.054</td>\n",
       "      <td>389.500</td>\n",
       "      <td>99.91</td>\n",
       "      <td>54.39</td>\n",
       "      <td>310.98</td>\n",
       "      <td>241.71</td>\n",
       "      <td>123.31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>261.636</td>\n",
       "      <td>309.876</td>\n",
       "      <td>238.174</td>\n",
       "      <td>163.426</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>76.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number   arpu_6   arpu_7   arpu_8   arpu_9  onnet_mou_6  \\\n",
       "0     7000842753  197.385  214.816  213.803   21.100          NaN   \n",
       "1     7001865778   34.047  355.074  268.321   86.285        24.11   \n",
       "2     7001625959  167.690  189.058  210.226  290.714        11.54   \n",
       "3     7001204172  221.338  251.102  508.054  389.500        99.91   \n",
       "4     7000142493  261.636  309.876  238.174  163.426        50.31   \n",
       "\n",
       "   onnet_mou_7  onnet_mou_8  onnet_mou_9  offnet_mou_6  ...    fb_user_6  \\\n",
       "0          NaN         0.00          NaN           NaN  ...          1.0   \n",
       "1        78.68         7.68        18.34         15.74  ...          NaN   \n",
       "2        55.24        37.26        74.81        143.33  ...          NaN   \n",
       "3        54.39       310.98       241.71        123.31  ...          NaN   \n",
       "4       149.44        83.89        58.78         76.96  ...          0.0   \n",
       "\n",
       "   fb_user_7  fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        1.0        1.0        NaN   968        30.4         0.0      101.20   \n",
       "1        1.0        1.0        NaN  1006         0.0         0.0        0.00   \n",
       "2        NaN        NaN        1.0  1103         0.0         0.0        4.17   \n",
       "3        NaN        NaN        NaN  2491         0.0         0.0        0.00   \n",
       "4        NaN        NaN        NaN  1526         0.0         0.0        0.00   \n",
       "\n",
       "   sep_vbc_3g  churn  \n",
       "0        3.58      1  \n",
       "1        0.00      0  \n",
       "2        0.00      0  \n",
       "3        0.00      0  \n",
       "4        0.00      0  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleting following columns as they have only 1 unique value, so not getting any information from these columns\n",
    "colList = temp1.colName.tolist()\n",
    "churn.drop(columns=colList, inplace=True)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "qyzgPs3ARPdy",
    "outputId": "3e0bf344-756d-45cc-b30a-93bb3af54285"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>34.047</td>\n",
       "      <td>355.074</td>\n",
       "      <td>268.321</td>\n",
       "      <td>24.11</td>\n",
       "      <td>78.68</td>\n",
       "      <td>7.68</td>\n",
       "      <td>15.74</td>\n",
       "      <td>99.84</td>\n",
       "      <td>304.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>167.690</td>\n",
       "      <td>189.058</td>\n",
       "      <td>210.226</td>\n",
       "      <td>11.54</td>\n",
       "      <td>55.24</td>\n",
       "      <td>37.26</td>\n",
       "      <td>143.33</td>\n",
       "      <td>220.59</td>\n",
       "      <td>208.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>221.338</td>\n",
       "      <td>251.102</td>\n",
       "      <td>508.054</td>\n",
       "      <td>99.91</td>\n",
       "      <td>54.39</td>\n",
       "      <td>310.98</td>\n",
       "      <td>123.31</td>\n",
       "      <td>109.01</td>\n",
       "      <td>71.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>261.636</td>\n",
       "      <td>309.876</td>\n",
       "      <td>238.174</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>76.96</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number   arpu_6   arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  \\\n",
       "0     7000842753  197.385  214.816  213.803          NaN          NaN   \n",
       "1     7001865778   34.047  355.074  268.321        24.11        78.68   \n",
       "2     7001625959  167.690  189.058  210.226        11.54        55.24   \n",
       "3     7001204172  221.338  251.102  508.054        99.91        54.39   \n",
       "4     7000142493  261.636  309.876  238.174        50.31       149.44   \n",
       "\n",
       "   onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  ...    sachet_3g_8  \\\n",
       "0         0.00           NaN           NaN          0.00  ...              0   \n",
       "1         7.68         15.74         99.84        304.76  ...              0   \n",
       "2        37.26        143.33        220.59        208.36  ...              0   \n",
       "3       310.98        123.31        109.01         71.68  ...              0   \n",
       "4        83.89         76.96         91.88        124.26  ...              0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        1.0        1.0        1.0   968        30.4         0.0      101.20   \n",
       "1        NaN        1.0        1.0  1006         0.0         0.0        0.00   \n",
       "2        NaN        NaN        NaN  1103         0.0         0.0        4.17   \n",
       "3        NaN        NaN        NaN  2491         0.0         0.0        0.00   \n",
       "4        0.0        NaN        NaN  1526         0.0         0.0        0.00   \n",
       "\n",
       "   sep_vbc_3g  churn  \n",
       "0        3.58      1  \n",
       "1        0.00      0  \n",
       "2        0.00      0  \n",
       "3        0.00      0  \n",
       "4        0.00      0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the columns which ends with _9, as we dont need to analyze the last month data \n",
    "churn.drop(columns= [col for col in churn if col.endswith('_9')], inplace=True)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the data \n",
    "\n",
    "churn['total_rech_data_6'].fillna(value = 0, inplace=True)\n",
    "churn['total_rech_data_7'].fillna(value = 0, inplace=True)\n",
    "churn['total_rech_data_8'].fillna(value = 0, inplace=True)\n",
    "\n",
    "churn['av_rech_amt_data_6'].fillna(value = 0, inplace=True)\n",
    "churn['av_rech_amt_data_7'].fillna(value = 0, inplace=True)\n",
    "churn['av_rech_amt_data_8'].fillna(value = 0, inplace=True)\n",
    "\n",
    "\n",
    "churn['max_rech_data_6'].fillna(value = 0, inplace=True)\n",
    "churn['max_rech_data_7'].fillna(value = 0, inplace=True)\n",
    "churn['max_rech_data_8'].fillna(value = 0, inplace=True)\n",
    "\n",
    "#Impute the data \n",
    "churn['night_pck_user_6'].fillna(value = -1, inplace=True)\n",
    "churn['night_pck_user_7'].fillna(value = -1, inplace=True)\n",
    "churn['night_pck_user_8'].fillna(value = -1, inplace=True)\n",
    "\n",
    "churn['fb_user_6'].fillna(value = -1, inplace=True)\n",
    "churn['fb_user_7'].fillna(value = -1, inplace=True)\n",
    "churn['fb_user_8'].fillna(value = -1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn['total_rech_data_amt_6'] = churn['total_rech_data_6'] * churn['av_rech_amt_data_6']\n",
    "churn['total_rech_data_amt_7'] = churn['total_rech_data_7'] * churn['av_rech_amt_data_7']\n",
    "churn['total_rech_data_amt_8'] = churn['total_rech_data_8'] * churn['av_rech_amt_data_8']\n",
    "\n",
    "churn['avg_total_rech_amt'] = (churn['total_rech_amt_6'] + churn['total_rech_amt_7'] + churn['total_rech_data_amt_6'] + churn['total_rech_data_amt_7'])/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D5Yse-RcT_DV",
    "outputId": "f5b80a5b-4b78-44c6-c4e4-cced4e2fc67c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#threshold value for the revenue is 70 percentile\n",
    "threshold_val = churn.avg_total_rech_amt.quantile(0.7)\n",
    "threshold_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RMJRU2v_UKCO",
    "outputId": "e5744dd0-a064-4efc-8b7d-e011b799a223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29953, 164)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter data based on the threshold value\n",
    "churn = churn.loc[churn.avg_total_rech_amt > threshold_val]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>date_of_last_rech_data_6</td>\n",
       "      <td>44.112443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>date_of_last_rech_data_7</td>\n",
       "      <td>43.117551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>date_of_last_rech_data_8</td>\n",
       "      <td>46.799987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>count_rech_2g_6</td>\n",
       "      <td>44.112443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>count_rech_2g_7</td>\n",
       "      <td>43.117551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>count_rech_2g_8</td>\n",
       "      <td>46.799987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>count_rech_3g_6</td>\n",
       "      <td>44.112443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>count_rech_3g_7</td>\n",
       "      <td>43.117551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>count_rech_3g_8</td>\n",
       "      <td>46.799987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>arpu_3g_6</td>\n",
       "      <td>44.112443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>arpu_3g_7</td>\n",
       "      <td>43.117551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>arpu_3g_8</td>\n",
       "      <td>46.799987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>arpu_2g_6</td>\n",
       "      <td>44.112443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>arpu_2g_7</td>\n",
       "      <td>43.117551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>arpu_2g_8</td>\n",
       "      <td>46.799987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      colName      count\n",
       "106  date_of_last_rech_data_6  44.112443\n",
       "107  date_of_last_rech_data_7  43.117551\n",
       "108  date_of_last_rech_data_8  46.799987\n",
       "115           count_rech_2g_6  44.112443\n",
       "116           count_rech_2g_7  43.117551\n",
       "117           count_rech_2g_8  46.799987\n",
       "118           count_rech_3g_6  44.112443\n",
       "119           count_rech_3g_7  43.117551\n",
       "120           count_rech_3g_8  46.799987\n",
       "130                 arpu_3g_6  44.112443\n",
       "131                 arpu_3g_7  43.117551\n",
       "132                 arpu_3g_8  46.799987\n",
       "133                 arpu_2g_6  44.112443\n",
       "134                 arpu_2g_7  43.117551\n",
       "135                 arpu_2g_8  46.799987"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will help us to identify, how many values are missing in each columns\n",
    "# also lets define the threshold 50%, if values are less than this\n",
    "# we need to decide, if is it good feature to keep ?\n",
    "\n",
    "temp = pd.DataFrame((churn.isnull().sum(axis=0)/churn.shape[0])*100)\n",
    "temp = temp.reset_index()\n",
    "temp.rename(columns={0:\"count\", \"index\":\"colName\"}, inplace=True)\n",
    "temp1 = temp.loc[temp['count'] > 10]\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KB2t_HhgVTg4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>churn</th>\n",
       "      <th>total_rech_data_amt_6</th>\n",
       "      <th>total_rech_data_amt_7</th>\n",
       "      <th>total_rech_data_amt_8</th>\n",
       "      <th>avg_total_rech_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>968</td>\n",
       "      <td>30.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7000701601</td>\n",
       "      <td>1069.180</td>\n",
       "      <td>1349.850</td>\n",
       "      <td>3171.480</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>...</td>\n",
       "      <td>802</td>\n",
       "      <td>57.74</td>\n",
       "      <td>19.38</td>\n",
       "      <td>18.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7001524846</td>\n",
       "      <td>378.721</td>\n",
       "      <td>492.223</td>\n",
       "      <td>137.362</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>94.66</td>\n",
       "      <td>80.63</td>\n",
       "      <td>136.48</td>\n",
       "      <td>...</td>\n",
       "      <td>315</td>\n",
       "      <td>21.03</td>\n",
       "      <td>910.65</td>\n",
       "      <td>122.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7002124215</td>\n",
       "      <td>514.453</td>\n",
       "      <td>597.753</td>\n",
       "      <td>637.760</td>\n",
       "      <td>102.41</td>\n",
       "      <td>132.11</td>\n",
       "      <td>85.14</td>\n",
       "      <td>757.93</td>\n",
       "      <td>896.68</td>\n",
       "      <td>983.39</td>\n",
       "      <td>...</td>\n",
       "      <td>720</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7000887461</td>\n",
       "      <td>74.350</td>\n",
       "      <td>193.897</td>\n",
       "      <td>366.966</td>\n",
       "      <td>48.96</td>\n",
       "      <td>50.66</td>\n",
       "      <td>33.58</td>\n",
       "      <td>85.41</td>\n",
       "      <td>89.36</td>\n",
       "      <td>205.89</td>\n",
       "      <td>...</td>\n",
       "      <td>604</td>\n",
       "      <td>40.45</td>\n",
       "      <td>51.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>583.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mobile_number    arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  \\\n",
       "0      7000842753   197.385   214.816   213.803          NaN          NaN   \n",
       "7      7000701601  1069.180  1349.850  3171.480        57.84        54.68   \n",
       "8      7001524846   378.721   492.223   137.362       413.69       351.03   \n",
       "21     7002124215   514.453   597.753   637.760       102.41       132.11   \n",
       "23     7000887461    74.350   193.897   366.966        48.96        50.66   \n",
       "\n",
       "    onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8         ...          \\\n",
       "0          0.00           NaN           NaN          0.00         ...           \n",
       "7         52.29        453.43        567.16        325.91         ...           \n",
       "8         35.08         94.66         80.63        136.48         ...           \n",
       "21        85.14        757.93        896.68        983.39         ...           \n",
       "23        33.58         85.41         89.36        205.89         ...           \n",
       "\n",
       "    aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  churn  \\\n",
       "0   968       30.40        0.00      101.20        3.58      1   \n",
       "7   802       57.74       19.38       18.74        0.00      1   \n",
       "8   315       21.03      910.65      122.16        0.00      0   \n",
       "21  720        0.00        0.00        0.00        0.00      0   \n",
       "23  604       40.45       51.86        0.00        0.00      0   \n",
       "\n",
       "    total_rech_data_amt_6  total_rech_data_amt_7  total_rech_data_amt_8  \\\n",
       "0                   252.0                  252.0                  252.0   \n",
       "7                     0.0                    0.0                    0.0   \n",
       "8                     0.0                  354.0                  207.0   \n",
       "21                    0.0                    0.0                    0.0   \n",
       "23                    0.0                  712.0                  540.0   \n",
       "\n",
       "    avg_total_rech_amt  \n",
       "0                559.0  \n",
       "7               1185.0  \n",
       "8                696.0  \n",
       "21               640.0  \n",
       "23               583.0  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colList = temp1.colName.tolist()\n",
    "churn.drop(columns=colList, inplace=True)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1058
    },
    "colab_type": "code",
    "id": "B4TV2bUUV87u",
    "outputId": "ed26e5f1-16ba-4385-cbad-6cc0a0a95bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobile_number            29953\n",
       "arpu_6                   29029\n",
       "arpu_7                   29040\n",
       "arpu_8                   28035\n",
       "onnet_mou_6              16872\n",
       "onnet_mou_7              16973\n",
       "onnet_mou_8              15854\n",
       "offnet_mou_6             21198\n",
       "offnet_mou_7             21233\n",
       "offnet_mou_8             20140\n",
       "roam_ic_mou_6             4045\n",
       "roam_ic_mou_7             3381\n",
       "roam_ic_mou_8             3431\n",
       "roam_og_mou_6             4742\n",
       "roam_og_mou_7             3988\n",
       "roam_og_mou_8             3996\n",
       "loc_og_t2t_mou_6         10416\n",
       "loc_og_t2t_mou_7         10388\n",
       "loc_og_t2t_mou_8         10056\n",
       "loc_og_t2m_mou_6         15607\n",
       "loc_og_t2m_mou_7         15659\n",
       "loc_og_t2m_mou_8         15118\n",
       "loc_og_t2f_mou_6          3089\n",
       "loc_og_t2f_mou_7          3097\n",
       "loc_og_t2f_mou_8          2988\n",
       "loc_og_t2c_mou_6          1682\n",
       "loc_og_t2c_mou_7          1763\n",
       "loc_og_t2c_mou_8          1720\n",
       "loc_og_mou_6             18334\n",
       "loc_og_mou_7             18493\n",
       "                         ...  \n",
       "vol_3g_mb_7              10830\n",
       "vol_3g_mb_8              10110\n",
       "night_pck_user_6             3\n",
       "night_pck_user_7             3\n",
       "night_pck_user_8             3\n",
       "monthly_2g_6                 5\n",
       "monthly_2g_7                 6\n",
       "monthly_2g_8                 6\n",
       "sachet_2g_6                 31\n",
       "sachet_2g_7                 35\n",
       "sachet_2g_8                 34\n",
       "monthly_3g_6                12\n",
       "monthly_3g_7                15\n",
       "monthly_3g_8                12\n",
       "sachet_3g_6                 25\n",
       "sachet_3g_7                 27\n",
       "sachet_3g_8                 29\n",
       "fb_user_6                    3\n",
       "fb_user_7                    3\n",
       "fb_user_8                    3\n",
       "aon                       3294\n",
       "aug_vbc_3g                9835\n",
       "jul_vbc_3g               10002\n",
       "jun_vbc_3g                9283\n",
       "sep_vbc_3g                2634\n",
       "churn                        2\n",
       "total_rech_data_amt_6     1642\n",
       "total_rech_data_amt_7     1746\n",
       "total_rech_data_amt_8     1619\n",
       "avg_total_rech_amt        5182\n",
       "Length: 149, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>onnet_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onnet_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>offnet_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>offnet_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roam_ic_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roam_ic_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roam_ic_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>roam_og_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>roam_og_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>loc_og_t2t_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loc_og_t2t_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>loc_og_t2m_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loc_og_t2f_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loc_og_t2f_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>loc_og_t2c_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>loc_og_t2c_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>loc_og_t2c_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>loc_og_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>loc_og_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>loc_og_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>std_og_t2t_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_og_t2t_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>std_og_t2t_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>loc_ic_t2f_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>loc_ic_t2f_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>loc_ic_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>std_ic_t2t_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>std_ic_t2t_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>std_ic_t2t_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>std_ic_t2m_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>std_ic_t2m_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>std_ic_t2m_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>std_ic_t2f_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>std_ic_t2f_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>std_ic_t2f_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>std_ic_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>std_ic_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>std_ic_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>spl_ic_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>spl_ic_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>isd_ic_mou_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>isd_ic_mou_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>isd_ic_mou_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ic_others_6</td>\n",
       "      <td>1.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ic_others_7</td>\n",
       "      <td>1.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ic_others_8</td>\n",
       "      <td>3.912797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>date_of_last_rech_6</td>\n",
       "      <td>0.243715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>date_of_last_rech_7</td>\n",
       "      <td>0.327179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>date_of_last_rech_8</td>\n",
       "      <td>1.943044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 colName     count\n",
       "4            onnet_mou_6  1.809502\n",
       "5            onnet_mou_7  1.789470\n",
       "6            onnet_mou_8  3.912797\n",
       "7           offnet_mou_6  1.809502\n",
       "8           offnet_mou_7  1.789470\n",
       "9           offnet_mou_8  3.912797\n",
       "10         roam_ic_mou_6  1.809502\n",
       "11         roam_ic_mou_7  1.789470\n",
       "12         roam_ic_mou_8  3.912797\n",
       "13         roam_og_mou_6  1.809502\n",
       "14         roam_og_mou_7  1.789470\n",
       "15         roam_og_mou_8  3.912797\n",
       "16      loc_og_t2t_mou_6  1.809502\n",
       "17      loc_og_t2t_mou_7  1.789470\n",
       "18      loc_og_t2t_mou_8  3.912797\n",
       "19      loc_og_t2m_mou_6  1.809502\n",
       "20      loc_og_t2m_mou_7  1.789470\n",
       "21      loc_og_t2m_mou_8  3.912797\n",
       "22      loc_og_t2f_mou_6  1.809502\n",
       "23      loc_og_t2f_mou_7  1.789470\n",
       "24      loc_og_t2f_mou_8  3.912797\n",
       "25      loc_og_t2c_mou_6  1.809502\n",
       "26      loc_og_t2c_mou_7  1.789470\n",
       "27      loc_og_t2c_mou_8  3.912797\n",
       "28          loc_og_mou_6  1.809502\n",
       "29          loc_og_mou_7  1.789470\n",
       "30          loc_og_mou_8  3.912797\n",
       "31      std_og_t2t_mou_6  1.809502\n",
       "32      std_og_t2t_mou_7  1.789470\n",
       "33      std_og_t2t_mou_8  3.912797\n",
       "..                   ...       ...\n",
       "61      loc_ic_t2f_mou_6  1.809502\n",
       "62      loc_ic_t2f_mou_7  1.789470\n",
       "63      loc_ic_t2f_mou_8  3.912797\n",
       "64          loc_ic_mou_6  1.809502\n",
       "65          loc_ic_mou_7  1.789470\n",
       "66          loc_ic_mou_8  3.912797\n",
       "67      std_ic_t2t_mou_6  1.809502\n",
       "68      std_ic_t2t_mou_7  1.789470\n",
       "69      std_ic_t2t_mou_8  3.912797\n",
       "70      std_ic_t2m_mou_6  1.809502\n",
       "71      std_ic_t2m_mou_7  1.789470\n",
       "72      std_ic_t2m_mou_8  3.912797\n",
       "73      std_ic_t2f_mou_6  1.809502\n",
       "74      std_ic_t2f_mou_7  1.789470\n",
       "75      std_ic_t2f_mou_8  3.912797\n",
       "76          std_ic_mou_6  1.809502\n",
       "77          std_ic_mou_7  1.789470\n",
       "78          std_ic_mou_8  3.912797\n",
       "82          spl_ic_mou_6  1.809502\n",
       "83          spl_ic_mou_7  1.789470\n",
       "84          spl_ic_mou_8  3.912797\n",
       "85          isd_ic_mou_6  1.809502\n",
       "86          isd_ic_mou_7  1.789470\n",
       "87          isd_ic_mou_8  3.912797\n",
       "88           ic_others_6  1.809502\n",
       "89           ic_others_7  1.789470\n",
       "90           ic_others_8  3.912797\n",
       "100  date_of_last_rech_6  0.243715\n",
       "101  date_of_last_rech_7  0.327179\n",
       "102  date_of_last_rech_8  1.943044\n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame((churn.isnull().sum(axis=0)/churn.shape[0])*100)\n",
    "temp = temp.reset_index()\n",
    "temp.rename(columns={0:\"count\", \"index\":\"colName\"}, inplace=True)\n",
    "temp1 = temp.loc[temp['count'] > 0]\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing categorical variable analysis for 'fb_user_6' column\n",
    "\n",
    "fb_user_6_postive_one_rows = churn.loc[churn['fb_user_6'] == 1.0]\n",
    "\n",
    "positive_one_churn_fraction = fb_user_6_postive_one_rows[\"churn\"].sum()/fb_user_6_postive_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_6'] == 1.0, ['fb_user_6']] = positive_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_6'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_user_6_zero_rows = churn.loc[churn['fb_user_6'] == 0.0]\n",
    "\n",
    "zero_churn_fraction = fb_user_6_zero_rows[\"churn\"].sum()/fb_user_6_zero_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_6'] == 0.0, ['fb_user_6']] = zero_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_6'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_user_6_negative_one_rows = churn.loc[churn['fb_user_6'] == -1.0]\n",
    "\n",
    "negative_one_churn_fraction = fb_user_6_negative_one_rows[\"churn\"].sum()/fb_user_6_negative_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_6'] == -1.0, ['fb_user_6']] = negative_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_6'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing categorical variable analysis for 'fb_user_7' column\n",
    "\n",
    "fb_user_7_postive_one_rows = churn.loc[churn['fb_user_7'] == 1.0]\n",
    "\n",
    "positive_one_churn_fraction = fb_user_7_postive_one_rows[\"churn\"].sum()/fb_user_7_postive_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_7'] == 1.0, ['fb_user_7']] = positive_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_7'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_user_7_zero_rows = churn.loc[churn['fb_user_7'] == 0.0]\n",
    "\n",
    "zero_churn_fraction = fb_user_7_zero_rows[\"churn\"].sum()/fb_user_7_zero_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_7'] == 0.0, ['fb_user_7']] = zero_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_7'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_user_7_negative_one_rows = churn.loc[churn['fb_user_7'] == -1.0]\n",
    "\n",
    "negative_one_churn_fraction = fb_user_7_negative_one_rows[\"churn\"].sum()/fb_user_7_negative_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_7'] == -1.0, ['fb_user_7']] = negative_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_7'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing categorical variable analysis for 'fb_user_8' column\n",
    "\n",
    "fb_user_8_postive_one_rows = churn.loc[churn['fb_user_8'] == 1.0]\n",
    "\n",
    "positive_one_churn_fraction = fb_user_8_postive_one_rows[\"churn\"].sum()/fb_user_8_postive_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_8'] == 1.0, ['fb_user_8']] = positive_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_8'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_user_8_zero_rows = churn.loc[churn['fb_user_8'] == 0.0]\n",
    "\n",
    "zero_churn_fraction = fb_user_8_zero_rows[\"churn\"].sum()/fb_user_8_zero_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_8'] == 0.0, ['fb_user_8']] = zero_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_8'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_user_8_negative_one_rows = churn.loc[churn['fb_user_8'] == -1.0]\n",
    "\n",
    "negative_one_churn_fraction = fb_user_8_negative_one_rows[\"churn\"].sum()/fb_user_8_negative_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['fb_user_8'] == -1.0, ['fb_user_8']] = negative_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['fb_user_8'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing categorical variable analysis for 'night_pck_user_6' column\n",
    "\n",
    "night_pck_user_6_postive_one_rows = churn.loc[churn['night_pck_user_6'] == 1.0]\n",
    "\n",
    "positive_one_churn_fraction = night_pck_user_6_postive_one_rows[\"churn\"].sum()/night_pck_user_6_postive_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_6'] == 1.0, ['night_pck_user_6']] = positive_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['night_pck_user_6'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "night_pck_user_6_zero_rows = churn.loc[churn['night_pck_user_6'] == 0.0]\n",
    "\n",
    "zero_churn_fraction = night_pck_user_6_zero_rows[\"churn\"].sum()/night_pck_user_6_zero_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_6'] == 0.0, ['night_pck_user_6']] = zero_churn_fraction.round(5)\n",
    "\n",
    "# churn['night_pck_user_6'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_pck_user_6_negative_one_rows = churn.loc[churn['night_pck_user_6'] == -1.0]\n",
    "\n",
    "negative_one_churn_fraction = night_pck_user_6_negative_one_rows[\"churn\"].sum()/night_pck_user_6_negative_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_6'] == -1.0, ['night_pck_user_6']] = negative_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['night_pck_user_6'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing categorical variable analysis for 'night_pck_user_7' column\n",
    "\n",
    "night_pck_user_7_postive_one_rows = churn.loc[churn['night_pck_user_7'] == 1.0]\n",
    "\n",
    "positive_one_churn_fraction = night_pck_user_7_postive_one_rows[\"churn\"].sum()/night_pck_user_7_postive_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_7'] == 1.0, ['night_pck_user_7']] = positive_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['night_pck_user_7'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_pck_user_7_zero_rows = churn.loc[churn['night_pck_user_7'] == 0.0]\n",
    "\n",
    "zero_churn_fraction = night_pck_user_7_zero_rows[\"churn\"].sum()/night_pck_user_7_zero_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_7'] == 0.0, ['night_pck_user_7']] = zero_churn_fraction.round(5)\n",
    "\n",
    "# churn['night_pck_user_7'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_pck_user_7_negative_one_rows = churn.loc[churn['night_pck_user_7'] == -1.0]\n",
    "\n",
    "negative_one_churn_fraction = night_pck_user_7_negative_one_rows[\"churn\"].sum()/night_pck_user_7_negative_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_7'] == -1.0, ['night_pck_user_7']] = negative_one_churn_fraction.round(5)\n",
    "\n",
    "# churn['night_pck_user_7'].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing categorical variable analysis for 'night_pck_user_8' column\n",
    "\n",
    "night_pck_user_8_postive_one_rows = churn.loc[churn['night_pck_user_8'] == 1.0]\n",
    "\n",
    "positive_one_churn_fraction = night_pck_user_8_postive_one_rows[\"churn\"].sum()/night_pck_user_8_postive_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_8'] == 1.0, ['night_pck_user_8']] = positive_one_churn_fraction.round(5)\n",
    "\n",
    "#churn['night_pck_user_8'].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_pck_user_8_zero_rows = churn.loc[churn['night_pck_user_8'] == 0.0]\n",
    "\n",
    "zero_churn_fraction = night_pck_user_8_zero_rows[\"churn\"].sum()/night_pck_user_8_zero_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_8'] == 0.0, ['night_pck_user_8']] = zero_churn_fraction.round(5)\n",
    "\n",
    "#churn['night_pck_user_8'].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_pck_user_8_negative_one_rows = churn.loc[churn['night_pck_user_8'] == -1.0]\n",
    "\n",
    "negative_one_churn_fraction = night_pck_user_8_negative_one_rows[\"churn\"].sum()/night_pck_user_8_negative_one_rows[\"churn\"].count()\n",
    "\n",
    "churn.loc[churn['night_pck_user_8'] == -1.0, ['night_pck_user_8']] = negative_one_churn_fraction.round(5)\n",
    "\n",
    "#churn['night_pck_user_8'].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29953, 146)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn1 = churn.select_dtypes(include=[np.float64, np.int64])\n",
    "\n",
    "churn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobile_number            0\n",
       "arpu_6                   0\n",
       "arpu_7                   0\n",
       "arpu_8                   0\n",
       "onnet_mou_6              0\n",
       "onnet_mou_7              0\n",
       "onnet_mou_8              0\n",
       "offnet_mou_6             0\n",
       "offnet_mou_7             0\n",
       "offnet_mou_8             0\n",
       "roam_ic_mou_6            0\n",
       "roam_ic_mou_7            0\n",
       "roam_ic_mou_8            0\n",
       "roam_og_mou_6            0\n",
       "roam_og_mou_7            0\n",
       "roam_og_mou_8            0\n",
       "loc_og_t2t_mou_6         0\n",
       "loc_og_t2t_mou_7         0\n",
       "loc_og_t2t_mou_8         0\n",
       "loc_og_t2m_mou_6         0\n",
       "loc_og_t2m_mou_7         0\n",
       "loc_og_t2m_mou_8         0\n",
       "loc_og_t2f_mou_6         0\n",
       "loc_og_t2f_mou_7         0\n",
       "loc_og_t2f_mou_8         0\n",
       "loc_og_t2c_mou_6         0\n",
       "loc_og_t2c_mou_7         0\n",
       "loc_og_t2c_mou_8         0\n",
       "loc_og_mou_6             0\n",
       "loc_og_mou_7             0\n",
       "                        ..\n",
       "vol_3g_mb_7              0\n",
       "vol_3g_mb_8              0\n",
       "night_pck_user_6         0\n",
       "night_pck_user_7         0\n",
       "night_pck_user_8         0\n",
       "monthly_2g_6             0\n",
       "monthly_2g_7             0\n",
       "monthly_2g_8             0\n",
       "sachet_2g_6              0\n",
       "sachet_2g_7              0\n",
       "sachet_2g_8              0\n",
       "monthly_3g_6             0\n",
       "monthly_3g_7             0\n",
       "monthly_3g_8             0\n",
       "sachet_3g_6              0\n",
       "sachet_3g_7              0\n",
       "sachet_3g_8              0\n",
       "fb_user_6                0\n",
       "fb_user_7                0\n",
       "fb_user_8                0\n",
       "aon                      0\n",
       "aug_vbc_3g               0\n",
       "jul_vbc_3g               0\n",
       "jun_vbc_3g               0\n",
       "sep_vbc_3g               0\n",
       "churn                    0\n",
       "total_rech_data_amt_6    0\n",
       "total_rech_data_amt_7    0\n",
       "total_rech_data_amt_8    0\n",
       "avg_total_rech_amt       0\n",
       "Length: 146, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = churn1['churn']\n",
    "churn1 = churn1.drop([\"churn\"],axis=1)\n",
    "normalized_churn=(churn1-churn1.mean())/churn1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [colName, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame((normalized_churn.isnull().sum(axis=0)/normalized_churn.shape[0])*100)\n",
    "temp = temp.reset_index()\n",
    "temp.rename(columns={0:\"count\", \"index\":\"colName\"}, inplace=True)\n",
    "temp1 = temp.loc[temp['count'] > 1]\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>total_rech_data_amt_6</th>\n",
       "      <th>total_rech_data_amt_7</th>\n",
       "      <th>total_rech_data_amt_8</th>\n",
       "      <th>avg_total_rech_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16686</th>\n",
       "      <td>0.025072</td>\n",
       "      <td>0.643452</td>\n",
       "      <td>0.295810</td>\n",
       "      <td>-0.101600</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>-0.192665</td>\n",
       "      <td>0.418799</td>\n",
       "      <td>0.776892</td>\n",
       "      <td>1.818390</td>\n",
       "      <td>3.271184</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050719</td>\n",
       "      <td>-0.742891</td>\n",
       "      <td>-0.40196</td>\n",
       "      <td>-0.403504</td>\n",
       "      <td>-0.380662</td>\n",
       "      <td>-0.153355</td>\n",
       "      <td>-0.321464</td>\n",
       "      <td>-0.358106</td>\n",
       "      <td>-0.285521</td>\n",
       "      <td>-0.217502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84709</th>\n",
       "      <td>0.452496</td>\n",
       "      <td>-0.857850</td>\n",
       "      <td>-0.960660</td>\n",
       "      <td>0.244054</td>\n",
       "      <td>-0.429545</td>\n",
       "      <td>-0.501874</td>\n",
       "      <td>0.838676</td>\n",
       "      <td>-0.464446</td>\n",
       "      <td>-0.689716</td>\n",
       "      <td>-0.211201</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050719</td>\n",
       "      <td>-1.065623</td>\n",
       "      <td>-0.40196</td>\n",
       "      <td>-0.403504</td>\n",
       "      <td>-0.380662</td>\n",
       "      <td>-0.153355</td>\n",
       "      <td>-0.321464</td>\n",
       "      <td>-0.358106</td>\n",
       "      <td>-0.285521</td>\n",
       "      <td>-0.486712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33699</th>\n",
       "      <td>-0.826657</td>\n",
       "      <td>-0.926473</td>\n",
       "      <td>-0.679675</td>\n",
       "      <td>-0.565226</td>\n",
       "      <td>-0.557547</td>\n",
       "      <td>-0.499738</td>\n",
       "      <td>-0.699983</td>\n",
       "      <td>-0.740582</td>\n",
       "      <td>-0.544608</td>\n",
       "      <td>-0.211201</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.003029</td>\n",
       "      <td>-0.338692</td>\n",
       "      <td>-0.40196</td>\n",
       "      <td>-0.403504</td>\n",
       "      <td>-0.380662</td>\n",
       "      <td>-0.153355</td>\n",
       "      <td>0.610413</td>\n",
       "      <td>0.205837</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>0.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25535</th>\n",
       "      <td>0.979690</td>\n",
       "      <td>0.486989</td>\n",
       "      <td>0.698290</td>\n",
       "      <td>2.761923</td>\n",
       "      <td>2.557193</td>\n",
       "      <td>2.696592</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>-0.363472</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>-0.211201</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050719</td>\n",
       "      <td>-0.971624</td>\n",
       "      <td>-0.40196</td>\n",
       "      <td>-0.403504</td>\n",
       "      <td>-0.380662</td>\n",
       "      <td>-0.153355</td>\n",
       "      <td>-0.321464</td>\n",
       "      <td>-0.358106</td>\n",
       "      <td>-0.285521</td>\n",
       "      <td>-0.040971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49976</th>\n",
       "      <td>-0.909978</td>\n",
       "      <td>-1.029361</td>\n",
       "      <td>-0.650999</td>\n",
       "      <td>-0.522212</td>\n",
       "      <td>-0.540017</td>\n",
       "      <td>-0.454179</td>\n",
       "      <td>-0.538458</td>\n",
       "      <td>-0.648263</td>\n",
       "      <td>-0.303605</td>\n",
       "      <td>-0.211201</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.003029</td>\n",
       "      <td>-0.579958</td>\n",
       "      <td>2.81699</td>\n",
       "      <td>0.227044</td>\n",
       "      <td>-0.380662</td>\n",
       "      <td>4.498526</td>\n",
       "      <td>0.112426</td>\n",
       "      <td>0.058927</td>\n",
       "      <td>-0.190684</td>\n",
       "      <td>-0.319375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "16686  0.025072  0.643452  0.295810    -0.101600    -0.146765    -0.192665   \n",
       "84709  0.452496 -0.857850 -0.960660     0.244054    -0.429545    -0.501874   \n",
       "33699 -0.826657 -0.926473 -0.679675    -0.565226    -0.557547    -0.499738   \n",
       "25535  0.979690  0.486989  0.698290     2.761923     2.557193     2.696592   \n",
       "49976 -0.909978 -1.029361 -0.650999    -0.522212    -0.540017    -0.454179   \n",
       "\n",
       "       offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  \\\n",
       "16686      0.418799      0.776892      1.818390       3.271184   \n",
       "84709      0.838676     -0.464446     -0.689716      -0.211201   \n",
       "33699     -0.699983     -0.740582     -0.544608      -0.211201   \n",
       "25535      0.045658     -0.363472      0.016218      -0.211201   \n",
       "49976     -0.538458     -0.648263     -0.303605      -0.211201   \n",
       "\n",
       "              ...          fb_user_8       aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "16686         ...           1.050719 -0.742891    -0.40196   -0.403504   \n",
       "84709         ...           1.050719 -1.065623    -0.40196   -0.403504   \n",
       "33699         ...          -1.003029 -0.338692    -0.40196   -0.403504   \n",
       "25535         ...           1.050719 -0.971624    -0.40196   -0.403504   \n",
       "49976         ...          -1.003029 -0.579958     2.81699    0.227044   \n",
       "\n",
       "       jun_vbc_3g  sep_vbc_3g  total_rech_data_amt_6  total_rech_data_amt_7  \\\n",
       "16686   -0.380662   -0.153355              -0.321464              -0.358106   \n",
       "84709   -0.380662   -0.153355              -0.321464              -0.358106   \n",
       "33699   -0.380662   -0.153355               0.610413               0.205837   \n",
       "25535   -0.380662   -0.153355              -0.321464              -0.358106   \n",
       "49976   -0.380662    4.498526               0.112426               0.058927   \n",
       "\n",
       "       total_rech_data_amt_8  avg_total_rech_amt  \n",
       "16686              -0.285521           -0.217502  \n",
       "84709              -0.285521           -0.486712  \n",
       "33699               0.099369            0.071200  \n",
       "25535              -0.285521           -0.040971  \n",
       "49976              -0.190684           -0.319375  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X = normalized_churn.drop([\"mobile_number\"],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20967, 53)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pca2 = pca.fit_transform(X_train)\n",
    "df_train_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca2 = LogisticRegression(class_weight=\"balanced\")\n",
    "model_pca2 = learner_pca2.fit(df_train_pca2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8986, 53)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pca2 = pca.transform(X_test)\n",
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.90'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_test2 = model_pca2.predict_proba(df_test_pca2)[:,1]\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test2 = model_pca2.predict(df_test_pca2)\n",
    "# \"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6689, 1616],\n",
       "       [ 106,  575]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, pred_probs_test2)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808368573336301"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred_probs_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "rfc.fit(df_train_pca2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      8305\n",
      "          1       0.57      0.14      0.22       681\n",
      "\n",
      "avg / total       0.91      0.93      0.91      8986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rfc.predict(df_test_pca2)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8233   72]\n",
      " [ 587   94]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9266636990874694\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity 0.9334467120181406\n"
     ]
    }
   ],
   "source": [
    "TP = confusion[0,0] # true positive\n",
    "TN = confusion[1,1] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "print(\"Sensitivity\", TP / float(TP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 0.5662650602409639\n"
     ]
    }
   ],
   "source": [
    "print(\"Specificity\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.991330523780855\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision\", TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(2, 20, 5)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning max depth\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 5)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "gridSearch = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "gridSearch.fit(df_train_pca2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.809251</td>\n",
       "      <td>0.738436</td>\n",
       "      <td>0.791319</td>\n",
       "      <td>0.781779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783231</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>4</td>\n",
       "      <td>0.819651</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.785740</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.791403</td>\n",
       "      <td>0.787988</td>\n",
       "      <td>0.020371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529666</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.866476</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.877176</td>\n",
       "      <td>0.861913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868842</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>3</td>\n",
       "      <td>0.901568</td>\n",
       "      <td>0.886663</td>\n",
       "      <td>0.888041</td>\n",
       "      <td>0.892691</td>\n",
       "      <td>0.891439</td>\n",
       "      <td>0.892080</td>\n",
       "      <td>0.005224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697511</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>0.904864</td>\n",
       "      <td>0.915355</td>\n",
       "      <td>0.914858</td>\n",
       "      <td>0.904364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908380</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>2</td>\n",
       "      <td>0.960055</td>\n",
       "      <td>0.958982</td>\n",
       "      <td>0.959223</td>\n",
       "      <td>0.957255</td>\n",
       "      <td>0.958567</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.748076</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>0.910110</td>\n",
       "      <td>0.924654</td>\n",
       "      <td>0.920820</td>\n",
       "      <td>0.916289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917251</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.977166</td>\n",
       "      <td>0.976392</td>\n",
       "      <td>0.975677</td>\n",
       "      <td>0.977704</td>\n",
       "      <td>0.976058</td>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.202350      0.003248         0.004505        0.000309   \n",
       "1       0.529666      0.002679         0.005377        0.000093   \n",
       "2       0.697511      0.010550         0.006312        0.000405   \n",
       "3       0.748076      0.011966         0.007298        0.001143   \n",
       "\n",
       "  param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0               2   {'max_depth': 2}           0.809251           0.738436   \n",
       "1               7   {'max_depth': 7}           0.866476           0.869099   \n",
       "2              12  {'max_depth': 12}           0.904864           0.915355   \n",
       "3              17  {'max_depth': 17}           0.910110           0.924654   \n",
       "\n",
       "   split2_test_score  split3_test_score       ...         mean_test_score  \\\n",
       "0           0.791319           0.781779       ...                0.783231   \n",
       "1           0.877176           0.861913       ...                0.868842   \n",
       "2           0.914858           0.904364       ...                0.908380   \n",
       "3           0.920820           0.916289       ...                0.917251   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.024079                4            0.819651            0.755500   \n",
       "1        0.004972                3            0.901568            0.886663   \n",
       "2        0.005553                2            0.960055            0.958982   \n",
       "3        0.005054                1            0.973350            0.977166   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.785740            0.787648            0.791403   \n",
       "1            0.888041            0.892691            0.891439   \n",
       "2            0.959223            0.957255            0.958567   \n",
       "3            0.976392            0.975677            0.977704   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.787988         0.020371  \n",
       "1          0.892080         0.005224  \n",
       "2          0.958816         0.000919  \n",
       "3          0.976058         0.001518  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = gridSearch.cv_results_\n",
    "pd.DataFrame(scores).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.9172509181094101 using {'max_depth': 17}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',gridSearch.best_score_,'using',gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tuning max depth\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 2\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# # instantiate the model (note we are specifying a max_depth)\n",
    "# rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# gridSearch = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# gridSearch.fit(df_train_pca2, y_train)\n",
    "\n",
    "# scores = gridSearch.cv_results_\n",
    "# pd.DataFrame(scores).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('We can get accuracy of',gridSearch.best_score_,'using',gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting accuracies with n_estimators\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_n_estimators\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_n_estimators\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"n_estimators\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454107</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_features': 4}</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>0.924893</td>\n",
       "      <td>0.921297</td>\n",
       "      <td>0.914620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917632</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.978179</td>\n",
       "      <td>0.980565</td>\n",
       "      <td>0.976809</td>\n",
       "      <td>0.978240</td>\n",
       "      <td>0.979229</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866118</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_features': 8}</td>\n",
       "      <td>0.911540</td>\n",
       "      <td>0.923701</td>\n",
       "      <td>0.924398</td>\n",
       "      <td>0.917959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917728</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975496</td>\n",
       "      <td>0.974244</td>\n",
       "      <td>0.978717</td>\n",
       "      <td>0.978777</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.977083</td>\n",
       "      <td>0.001861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.475620</td>\n",
       "      <td>0.030812</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_features': 14}</td>\n",
       "      <td>0.912256</td>\n",
       "      <td>0.925370</td>\n",
       "      <td>0.921059</td>\n",
       "      <td>0.918435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917394</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976808</td>\n",
       "      <td>0.975735</td>\n",
       "      <td>0.970371</td>\n",
       "      <td>0.974902</td>\n",
       "      <td>0.975379</td>\n",
       "      <td>0.974639</td>\n",
       "      <td>0.002224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.160684</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 20}</td>\n",
       "      <td>0.909394</td>\n",
       "      <td>0.920839</td>\n",
       "      <td>0.921059</td>\n",
       "      <td>0.915097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915820</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>5</td>\n",
       "      <td>0.973887</td>\n",
       "      <td>0.974304</td>\n",
       "      <td>0.970848</td>\n",
       "      <td>0.973352</td>\n",
       "      <td>0.973530</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.504807</td>\n",
       "      <td>0.051055</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>24</td>\n",
       "      <td>{'max_features': 24}</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.922508</td>\n",
       "      <td>0.921059</td>\n",
       "      <td>0.917959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916345</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>4</td>\n",
       "      <td>0.973827</td>\n",
       "      <td>0.971144</td>\n",
       "      <td>0.973054</td>\n",
       "      <td>0.971802</td>\n",
       "      <td>0.974782</td>\n",
       "      <td>0.972922</td>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.454107      0.008947         0.006743        0.000108   \n",
       "1       0.866118      0.032961         0.006614        0.000393   \n",
       "2       1.475620      0.030812         0.006740        0.000549   \n",
       "3       2.160684      0.070072         0.006589        0.000250   \n",
       "4       2.504807      0.051055         0.006232        0.000070   \n",
       "\n",
       "  param_max_features                params  split0_test_score  \\\n",
       "0                  4   {'max_features': 4}           0.912017   \n",
       "1                  8   {'max_features': 8}           0.911540   \n",
       "2                 14  {'max_features': 14}           0.912256   \n",
       "3                 20  {'max_features': 20}           0.909394   \n",
       "4                 24  {'max_features': 24}           0.909871   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.924893           0.921297           0.914620       ...          \n",
       "1           0.923701           0.924398           0.917959       ...          \n",
       "2           0.925370           0.921059           0.918435       ...          \n",
       "3           0.920839           0.921059           0.915097       ...          \n",
       "4           0.922508           0.921059           0.917959       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.917632        0.004734                2            0.982353   \n",
       "1         0.917728        0.005713                1            0.975496   \n",
       "2         0.917394        0.005682                3            0.976808   \n",
       "3         0.915820        0.004563                5            0.973887   \n",
       "4         0.916345        0.005309                4            0.973827   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.978179            0.980565            0.976809   \n",
       "1            0.974244            0.978717            0.978777   \n",
       "2            0.975735            0.970371            0.974902   \n",
       "3            0.974304            0.970848            0.973352   \n",
       "4            0.971144            0.973054            0.971802   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.978240          0.979229         0.001974  \n",
       "1            0.978181          0.977083         0.001861  \n",
       "2            0.975379          0.974639         0.002224  \n",
       "3            0.973530          0.973184         0.001213  \n",
       "4            0.974782          0.972922         0.001320  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [4, 8, 14, 20, 24]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=17, class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "gridSearch = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "gridSearch.fit(df_train_pca2, y_train)\n",
    "\n",
    "scores = gridSearch.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.9177278580626699 using {'max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',gridSearch.best_score_,'using',gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552447</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 100}</td>\n",
       "      <td>0.838102</td>\n",
       "      <td>0.851693</td>\n",
       "      <td>0.859051</td>\n",
       "      <td>0.843310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848524</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861325</td>\n",
       "      <td>0.858880</td>\n",
       "      <td>0.863897</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.858352</td>\n",
       "      <td>0.861616</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485402</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 150}</td>\n",
       "      <td>0.835002</td>\n",
       "      <td>0.838817</td>\n",
       "      <td>0.853565</td>\n",
       "      <td>0.844741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841894</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>2</td>\n",
       "      <td>0.848745</td>\n",
       "      <td>0.847374</td>\n",
       "      <td>0.851556</td>\n",
       "      <td>0.857458</td>\n",
       "      <td>0.852271</td>\n",
       "      <td>0.851481</td>\n",
       "      <td>0.003485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.456288</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 200}</td>\n",
       "      <td>0.837148</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.847365</td>\n",
       "      <td>0.829001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837125</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>3</td>\n",
       "      <td>0.849997</td>\n",
       "      <td>0.841173</td>\n",
       "      <td>0.842912</td>\n",
       "      <td>0.844044</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.845424</td>\n",
       "      <td>0.003462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425853</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 250}</td>\n",
       "      <td>0.819504</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.839971</td>\n",
       "      <td>0.823277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830114</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>4</td>\n",
       "      <td>0.838371</td>\n",
       "      <td>0.836285</td>\n",
       "      <td>0.832479</td>\n",
       "      <td>0.836294</td>\n",
       "      <td>0.836592</td>\n",
       "      <td>0.836004</td>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409867</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>300</td>\n",
       "      <td>{'min_samples_leaf': 300}</td>\n",
       "      <td>0.824988</td>\n",
       "      <td>0.834764</td>\n",
       "      <td>0.823754</td>\n",
       "      <td>0.812068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824486</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>5</td>\n",
       "      <td>0.837894</td>\n",
       "      <td>0.838789</td>\n",
       "      <td>0.825981</td>\n",
       "      <td>0.833194</td>\n",
       "      <td>0.830154</td>\n",
       "      <td>0.833202</td>\n",
       "      <td>0.004789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.552447      0.032419         0.005664        0.000252   \n",
       "1       0.485402      0.008712         0.005236        0.000046   \n",
       "2       0.456288      0.007766         0.005141        0.000115   \n",
       "3       0.425853      0.008788         0.005044        0.000088   \n",
       "4       0.409867      0.007148         0.004941        0.000055   \n",
       "\n",
       "  param_min_samples_leaf                     params  split0_test_score  \\\n",
       "0                    100  {'min_samples_leaf': 100}           0.838102   \n",
       "1                    150  {'min_samples_leaf': 150}           0.835002   \n",
       "2                    200  {'min_samples_leaf': 200}           0.837148   \n",
       "3                    250  {'min_samples_leaf': 250}           0.819504   \n",
       "4                    300  {'min_samples_leaf': 300}           0.824988   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.851693           0.859051           0.843310       ...          \n",
       "1           0.838817           0.853565           0.844741       ...          \n",
       "2           0.832618           0.847365           0.829001       ...          \n",
       "3           0.836910           0.839971           0.823277       ...          \n",
       "4           0.834764           0.823754           0.812068       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.848524        0.007217                1            0.861325   \n",
       "1         0.841894        0.006663                2            0.848745   \n",
       "2         0.837125        0.006273                3            0.849997   \n",
       "3         0.830114        0.007789                4            0.838371   \n",
       "4         0.824486        0.007297                5            0.837894   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.858880            0.863897            0.865625   \n",
       "1            0.847374            0.851556            0.857458   \n",
       "2            0.841173            0.842912            0.844044   \n",
       "3            0.836285            0.832479            0.836294   \n",
       "4            0.838789            0.825981            0.833194   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.858352          0.861616         0.002811  \n",
       "1            0.852271          0.851481         0.003485  \n",
       "2            0.848992          0.845424         0.003462  \n",
       "3            0.836592          0.836004         0.001926  \n",
       "4            0.830154          0.833202         0.004789  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=17, class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "gridSearch = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "gridSearch.fit(df_train_pca2, y_train)\n",
    "\n",
    "scores = gridSearch.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.8485238708446606 using {'min_samples_leaf': 100}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',gridSearch.best_score_,'using',gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696322</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_split': 200}</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.872406</td>\n",
       "      <td>0.858574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886603</td>\n",
       "      <td>0.891373</td>\n",
       "      <td>0.885179</td>\n",
       "      <td>0.886074</td>\n",
       "      <td>0.880351</td>\n",
       "      <td>0.885916</td>\n",
       "      <td>0.003515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690746</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_split': 250}</td>\n",
       "      <td>0.860038</td>\n",
       "      <td>0.863853</td>\n",
       "      <td>0.863582</td>\n",
       "      <td>0.848319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857586</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883801</td>\n",
       "      <td>0.879091</td>\n",
       "      <td>0.873972</td>\n",
       "      <td>0.870693</td>\n",
       "      <td>0.872720</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.004763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644190</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>300</td>\n",
       "      <td>{'min_samples_split': 300}</td>\n",
       "      <td>0.853839</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>0.851658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856632</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873785</td>\n",
       "      <td>0.871818</td>\n",
       "      <td>0.872541</td>\n",
       "      <td>0.875343</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.617025</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>350</td>\n",
       "      <td>{'min_samples_split': 350}</td>\n",
       "      <td>0.837148</td>\n",
       "      <td>0.847401</td>\n",
       "      <td>0.860959</td>\n",
       "      <td>0.853565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850670</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.861861</td>\n",
       "      <td>0.856019</td>\n",
       "      <td>0.859127</td>\n",
       "      <td>0.867354</td>\n",
       "      <td>0.869143</td>\n",
       "      <td>0.862701</td>\n",
       "      <td>0.004925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615364</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>400</td>\n",
       "      <td>{'min_samples_split': 400}</td>\n",
       "      <td>0.835479</td>\n",
       "      <td>0.835956</td>\n",
       "      <td>0.855235</td>\n",
       "      <td>0.849273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845471</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>5</td>\n",
       "      <td>0.851964</td>\n",
       "      <td>0.853932</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.862943</td>\n",
       "      <td>0.861154</td>\n",
       "      <td>0.856107</td>\n",
       "      <td>0.005001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.696322      0.027322         0.006230        0.000664   \n",
       "1       0.690746      0.015080         0.006251        0.000648   \n",
       "2       0.644190      0.022633         0.005810        0.000355   \n",
       "3       0.617025      0.023738         0.005463        0.000098   \n",
       "4       0.615364      0.012571         0.005537        0.000316   \n",
       "\n",
       "  param_min_samples_split                      params  split0_test_score  \\\n",
       "0                     200  {'min_samples_split': 200}           0.862661   \n",
       "1                     250  {'min_samples_split': 250}           0.860038   \n",
       "2                     300  {'min_samples_split': 300}           0.853839   \n",
       "3                     350  {'min_samples_split': 350}           0.837148   \n",
       "4                     400  {'min_samples_split': 400}           0.835479   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.875536           0.872406           0.858574       ...          \n",
       "1           0.863853           0.863582           0.848319       ...          \n",
       "2           0.856700           0.864775           0.851658       ...          \n",
       "3           0.847401           0.860959           0.853565       ...          \n",
       "4           0.835956           0.855235           0.849273       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.865741        0.006926                1            0.886603   \n",
       "1         0.857586        0.006274                2            0.883801   \n",
       "2         0.856632        0.004451                3            0.873785   \n",
       "3         0.850670        0.008010                4            0.861861   \n",
       "4         0.845471        0.008192                5            0.851964   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.891373            0.885179            0.886074   \n",
       "1            0.879091            0.873972            0.870693   \n",
       "2            0.871818            0.872541            0.875343   \n",
       "3            0.856019            0.859127            0.867354   \n",
       "4            0.853932            0.850543            0.862943   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.880351          0.885916         0.003515  \n",
       "1            0.872720          0.876055         0.004763  \n",
       "2            0.874627          0.873623         0.001298  \n",
       "3            0.869143          0.862701         0.004925  \n",
       "4            0.861154          0.856107         0.005001  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=17, class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "gridSearch = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "\n",
    "gridSearch.fit(df_train_pca2, y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = gridSearch.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.8657414031573425 using {'min_samples_split': 200}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',gridSearch.best_score_,'using',gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkapil/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search to Find Optimal Hyperparameters\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200,300], \n",
    "    'max_features': [5, 8, 10]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [4, 8, 10], 'min_samples_leaf': range(100, 400, 200), 'min_samples_split': range(200, 500, 200), 'n_estimators': [100, 200, 300], 'max_features': [5, 8, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(df_train_pca2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.9178709400486479 using {'max_depth': 8, 'max_features': 10, 'min_samples_leaf': 100, 'min_samples_split': 200, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=8,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=300, \n",
    "                             class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=8, max_features=10,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=100,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(df_train_pca2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(df_test_pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.87      0.92      8305\n",
      "          1       0.32      0.75      0.45       681\n",
      "\n",
      "avg / total       0.93      0.86      0.89      8986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7242 1063]\n",
      " [ 170  511]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity 0.9334467120181406\n"
     ]
    }
   ],
   "source": [
    "TP = confusion[0,0] # true positive\n",
    "TN = confusion[1,1] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "print(\"Sensitivity\", TP / float(TP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 0.5662650602409639\n"
     ]
    }
   ],
   "source": [
    "print(\"Specificity\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.991330523780855\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision\", TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "telecom_churn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
